{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jash/anaconda3/envs/py27/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jash/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From <ipython-input-1-4bad5fe6c557>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/jash/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/jash/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/jash/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/jash/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/jash/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: __init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 10)\n"
     ]
    }
   ],
   "source": [
    "x_train=mnist.train.images.reshape(55000,28,28)\n",
    "y_train=mnist.train.labels\n",
    "print y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=x_train[:50][:][:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f=np.random.rand(3,3)\n",
    "out=np.zeros(shape=(image.shape[0],image.shape[1]))\n",
    "i_h=image.shape[1]\n",
    "i_w=image.shape[2]\n",
    "d=image.shape[0]\n",
    "f_h=f.shape[0]\n",
    "f_w=f.shape[1]\n",
    "p_h=1\n",
    "p_w=1\n",
    "output_list=[]\n",
    "\n",
    "s_w=2\n",
    "s_h=2\n",
    "\n",
    "\n",
    "#batch norm parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i tried vector form a[:][p+i][p+j]=image[:][i][j] but it was showing some error\n",
    "def padding(image,a):\n",
    "    \n",
    "    p=1\n",
    "    for k in range(image.shape[0]):\n",
    "        for i in range(image.shape[1]):\n",
    "                for j in range(image.shape[2]):\n",
    "                    a[k][p+i][p+j]=image[k][i][j]\n",
    "\n",
    "        \n",
    "            \n",
    "    return a\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad=1\n",
    "x=1*2+image.shape[1]\n",
    "a=np.zeros(shape=(image.shape[0],x,x))\n",
    "a=padding(image,a)\n",
    "gamma=np.random.rand(image.shape[1],image.shape[2])\n",
    "Beta=np.random.rand(image.shape[1],image.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve(image,fil):\n",
    "    out=[]\n",
    "    pad=1\n",
    "    \n",
    "    i_h=image.shape[1]\n",
    "    i_w=image.shape[2]\n",
    "    s_h=1\n",
    "    s_w=1\n",
    "    f_h=3\n",
    "    f_w=3  \n",
    "    k=0\n",
    "    l=i_h-f_h+1\n",
    "    y=0\n",
    "    u=0\n",
    "    \n",
    "    m=image.shape[0]\n",
    "    f=fil\n",
    "    k=1\n",
    "    count=0\n",
    "    #this is the required output image and that is 2 less than the padded image or equal to the before padded image\n",
    "    x=image.shape[1]-2\n",
    "    y=image.shape[2]-2\n",
    "    prod=x*y\n",
    "    conv=np.zeros(shape=(image.shape[0],3,3))\n",
    "    out=np.zeros(shape=(image.shape[0],x,y))\n",
    "    for k in range(m):\n",
    "        a=image[k]\n",
    "        for i in range(i_h-f_h+1):\n",
    "            for j in range(i_w-f_w+1):\n",
    "                        \n",
    "                summation=a[i:i+3,j:j+3]\n",
    "                \n",
    "                conv=summation*f\n",
    "                         \n",
    "                convolve=np.sum(conv)\n",
    "                \n",
    "                out[k][i][j]=convolve\n",
    "                \n",
    "    \n",
    "    return out                     \n",
    "                               \n",
    "           \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(image):\n",
    "    out=1/(1+np.exp(-1*image))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(image):\n",
    "    \n",
    "    image[image<0]=0\n",
    "    return image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool(image):\n",
    "    s=1\n",
    "    f=2\n",
    "    out=np.zeros(shape=(image.shape[0],image.shape[1]-1,image.shape[2]-1))\n",
    "    \n",
    "    for k in range(image.shape[0]):\n",
    "        for i in range(image.shape[1]-1):\n",
    "            for j in range(image.shape[2]-1):\n",
    "                maximum=0\n",
    "                for p in range(2):\n",
    "                    for q in range(2):\n",
    "                        if(image[k][i+p][j+q]>maximum):\n",
    "                            maximum=image[k][i+p][j+q]\n",
    "                out[k][i][j]=maximum\n",
    "                \n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sigmoid layer\n",
    "\n",
    "def forwardlayer(f,image,gamma,Beta):\n",
    "    #using formula to calculate padding\n",
    "    pad=1\n",
    "    x=1*2+image.shape[1]\n",
    "    a=np.zeros(shape=(image.shape[0],x,x))\n",
    "    a=padding(image,a)\n",
    "    eps=10e-7\n",
    "    conv=convolve(a,f)\n",
    "    N=image.shape[0]\n",
    "    #modification for batch norm\n",
    "    x=conv\n",
    "     #step1: calculate mean\n",
    "    mu = 1./N * np.sum(x, axis = 0)\n",
    "\n",
    "  #step2: subtract mean vector of every trainings example\n",
    "    xmu = x - mu\n",
    "\n",
    "  #step3: following the lower branch - calculation denominator\n",
    "    sq = xmu ** 2\n",
    "\n",
    "  #step4: calculate variance\n",
    "    var = 1./N * np.sum(sq, axis = 0)\n",
    "\n",
    "  #step5: add eps for numerical stability, then sqrt\n",
    "    sqrtvar = np.sqrt(var + eps)\n",
    "\n",
    "  #step6: invert sqrtwar\n",
    "    ivar = 1./sqrtvar\n",
    "\n",
    "  #step7: execute normalization\n",
    "    xhat = xmu * ivar\n",
    "\n",
    "  #step8: Nor the two transformation steps\n",
    "    gammax = gamma * xhat\n",
    "\n",
    "  #step9\n",
    "    out = gammax + Beta\n",
    "\n",
    "        \n",
    "    relu_output=relu(out)\n",
    "\n",
    "\n",
    "    \n",
    "    maxpoolout=maxpool(relu_output)\n",
    "    \n",
    "    return maxpoolout,xhat,gamma,xmu,ivar,sqrtvar,var,eps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxpool_out after layer 1 shape is  (50, 27, 27)\n"
     ]
    }
   ],
   "source": [
    "maxpool_out1,xhat,gamma,xmu,ivar,sqrtvar,var,eps=forwardlayer(f,image,gamma,Beta)\n",
    "print \"maxpool_out after layer 1 shape is \",maxpool_out1.shape\n",
    "maxpool_out2=maxpool_out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "product=maxpool_out2.shape[1]*maxpool_out2.shape[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 10)\n"
     ]
    }
   ],
   "source": [
    "final_input=maxpool_out2.reshape(maxpool_out2.shape[0],product)\n",
    "fc_weights=np.random.rand(10,product)\n",
    "final_output=np.dot(fc_weights,final_input.T)\n",
    "final_output=final_output.T\n",
    "print final_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(final_output):\n",
    "    softmax_in=np.exp(final_output)\n",
    "    softmax_output=np.zeros(final_output.shape)\n",
    "    denominator=np.sum(softmax_in,axis=0)\n",
    "    softmax_output=softmax_in/denominator\n",
    "    \n",
    "    return softmax_output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_classifier(softmax_output):\n",
    "    predict=np.zeros(shape=(softmax_output.shape[0],1))\n",
    "    pred=np.argmax(softmax_output,axis=1)\n",
    "    \n",
    "    predict=pred.reshape(len(pred),1)\n",
    "    predicted=np.zeros(shape=(predict.shape[0],10))\n",
    "    m=predict.shape[0]\n",
    "    for i in range(m):\n",
    "        for j in range(10):\n",
    "            if(predict[i][0]==j):\n",
    "                predicted[i][j]=1\n",
    "        \n",
    "    \n",
    "    \n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_input=softmax(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=softmax_classifier(classifier_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting to write functions for backprop ----forward prop done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_loss(target,classifier_input):\n",
    "    \n",
    "    predicted=classifier_input\n",
    "    diff=np.subtract(target,predicted)\n",
    "    m=target.shape[0]\n",
    "    \n",
    "    #softmax loss summed over all classes\n",
    "    loss=((-np.dot(target,(np.log(predicted.T+10e-9)))))/m\n",
    "                      \n",
    "    fin_loss=np.zeros(shape=(m,1))\n",
    "    \n",
    "    for k in range(m):\n",
    "        fin_loss[k]=loss[k][k]\n",
    "    #do sum\n",
    "    fin_loss_total=np.sum(fin_loss)/m\n",
    "    return fin_loss_total\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted shape (50, 10)\n",
      "0.35367707027588535\n"
     ]
    }
   ],
   "source": [
    "target=y_train[:50][:][:]\n",
    "print \"predicted shape\",predicted.shape\n",
    "\n",
    "\n",
    "loss=final_loss(target,predicted)\n",
    "print loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmaxlossgradient(target,predicted,weights,classifier_input):\n",
    "    w_width=weights.shape[1]\n",
    "    m=len(target)\n",
    "    gradient=np.zeros(shape=(m,10))\n",
    "    gradient=np.multiply(predicted,(target-predicted))\n",
    "    \n",
    "    return gradient\n",
    "                    \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient wrt fc layer weights\n",
    "\n",
    "def softmaxderivativewrtw(target,predicted,weights,classifier_input,x):\n",
    "    \n",
    "    #size of returned is mX10 i.e softmaxgradpower\n",
    "    #we want all weights gradient--grad--so shape is 10Xweights.shape[2]\n",
    "    #x shape is mXweights.shape[2]\n",
    "    \n",
    "    w_width=weights.shape[1]\n",
    "    softmaxgradwrtpower=softmaxlossgradient(target,predicted,weights,classifier_input)\n",
    "    \n",
    "    gradw=np.zeros(shape=(weights.shape))\n",
    "    product=x.shape[1]*x.shape[2]\n",
    "    a=x.reshape(target.shape[0],product)\n",
    "    gradw=np.matmul(softmaxgradwrtpower.T,a)\n",
    "    return gradw\n",
    "           \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient wrt input image\n",
    "\n",
    "def softmaxderivativewrtx(target,predicted,weights,classifier_input,x):\n",
    "    \n",
    "    #size of returned is mX10 i.e softmaxgradpower\n",
    "    #we want all weights gradient--grad--so shape is 10Xweights.shape[2]\n",
    "    #x shape is mXweights.shape[2]\n",
    "    \n",
    "    m=len(target)\n",
    "    w_width=weights.shape[1]\n",
    "    softmaxgradwrtpower=softmaxlossgradient(target,predicted,weights,classifier_input) \n",
    "    gradx=np.zeros(shape=(x.shape))\n",
    "    \n",
    "    gradx=np.matmul(softmaxgradwrtpower,weights)\n",
    "    a=math.sqrt(gradx.shape[1])\n",
    "    a=int(a)\n",
    "                \n",
    "    gradx=gradx.reshape(gradx.shape[0],a,a)\n",
    "                \n",
    "    \n",
    "    return gradx\n",
    "            \n",
    "                \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpoolderivative(convoutput,gradx,image):\n",
    "    s=1\n",
    "    f=2\n",
    "    largerderivative=np.zeros(shape=(image.shape))\n",
    "    \n",
    "    for k in range(image.shape[0]):\n",
    "        for i in range(image.shape[1]-1):\n",
    "            for j in range(image.shape[2]-1):\n",
    "                \n",
    "                maximum=0\n",
    "                alpha=i\n",
    "                beta=j\n",
    "                for p in range(2):\n",
    "                    for q in range(2):\n",
    "                        if(image[k][i+p][j+q]>maximum):\n",
    "                            maximum=image[k][i+p][j+q]\n",
    "                            alpha=i+p\n",
    "                            beta=j+q\n",
    "               \n",
    "                largerderivative[k][alpha][beta]=largerderivative[k][alpha][beta]+gradx[k][i][j]\n",
    "    \n",
    "    return largerderivative\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remember that the output here is the before maxpool output and not the after maxpool output\n",
    "#(outputfrom convolution,image,fc_weights,largerderivative,k)\n",
    "\n",
    "def convandreluderivativewrtw(output,x,convweights,gradx,k,gamma,Beta,alpha3,alpha4,image):\n",
    "    m=x.shape[0]    \n",
    "    gradconvweights=np.zeros(shape=(convweights.shape[0],convweights.shape[1]))\n",
    "    \n",
    "    h=output.shape[1]\n",
    "    w=output.shape[2]\n",
    "    eps=10e-7\n",
    "    product=gradx.shape[1]*gradx.shape[2]\n",
    "    gradx=gradx.reshape(gradx.shape[0],product)\n",
    "    #now gradx becomes 50X(28X28)\n",
    "    maxpool_out,xhat,gamma,xmu,ivar,sqrtvar,var,eps=forwardlayer(convweights,image,gamma,Beta)\n",
    "    dx,dgamma,dbeta=batchnorm_backward(gradx,xhat,gamma,xmu,ivar,sqrtvar,var,eps)\n",
    "    gamma=gamma.reshape(product)\n",
    "    Beta=Beta.reshape(product)\n",
    "    gamma=gamma-alpha3*dgamma\n",
    "    Beta=Beta-alpha4*dbeta\n",
    "    zeta=int(math.sqrt(product))\n",
    "    gamma=gamma.reshape(zeta,zeta)\n",
    "    Beta=Beta.reshape(zeta,zeta)\n",
    "    \n",
    "    \n",
    "    for i in range(h):\n",
    "            for j in range(w):\n",
    "                for p in range(3):\n",
    "                    for q in range(3):\n",
    "                        if(output[k][i][j]>0):\n",
    "                            gradconvweights[p][q]=gradconvweights[p][q]+dx[k][i][j]*x[k][i+p][j+q]                \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return gradconvweights,gamma,Beta\n",
    "    \n",
    "#output shape is  (50, 28, 28)\n",
    "#gradx[largerderivative is sent here] shape is (50, 28, 28)\n",
    "#x shape is  (50, 28, 28)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batchnorm i haven't written on my own but have understood it fully and can explain\n",
    "\n",
    "def batchnorm_backward(dout,xhat,gamma,xmu,ivar,sqrtvar,var,eps):\n",
    "    \n",
    "    \n",
    "    N,D = dout.shape\n",
    "    dbeta = np.sum(dout, axis=0)\n",
    "    dgammax = dout \n",
    "    p=xhat.reshape(xhat.shape[0],xhat.shape[1]*xhat.shape[2])\n",
    "    dgamma = np.sum(dgammax*p, axis=0)\n",
    "    g=gamma.reshape(1,gamma.shape[0]*gamma.shape[1])\n",
    "    dxhat = dgammax * g\n",
    "    xmu=xmu.reshape(xmu.shape[0],xmu.shape[1]*xmu.shape[2])\n",
    "    divar = np.sum(dxhat*xmu, axis=0)\n",
    "    ivar=ivar.reshape(ivar.shape[0]*ivar.shape[1])\n",
    "    dxmu1 = dxhat * ivar\n",
    "    zeta=int(sqrtvar.shape[0]*sqrtvar.shape[1])\n",
    "    sqrtvar=sqrtvar.reshape(zeta)\n",
    "    dsqrtvar = -1. /(sqrtvar**2) * divar\n",
    "    var=var.reshape(zeta)\n",
    "    \n",
    "    dvar = 0.5 * 1. /np.sqrt(var+eps) * dsqrtvar\n",
    "    dsq = 1. /N * np.ones((N,D)) * dvar\n",
    "    dxmu2 = 2 * xmu * dsq\n",
    "    dx1 = (dxmu1 + dxmu2)\n",
    "    dmu = -1 * np.sum(dxmu1+dxmu2, axis=0)\n",
    "    dx2 = 1. /N * np.ones((N,D)) * dmu\n",
    "    dx = dx1 + dx2\n",
    "    length=int(math.sqrt(dx.shape[1]))\n",
    "    dx=dx.reshape(dx.shape[0],length,length)\n",
    "    return dx, dgamma, dbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc_weights gradients iteration 0 example 0 are [[-6.17672972 -6.93683497 -6.93683497 ... -5.95306142 -5.95306142\n",
      "  -5.102142  ]\n",
      " [-7.05911968 -7.9278114  -7.9278114  ... -6.80349876 -6.80349876\n",
      "  -5.83101942]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [-2.64716988 -2.97292927 -2.97292927 ... -2.55131204 -2.55131204\n",
      "  -2.18663228]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]]\n",
      "loss after iteration 0 is 0.33157225337114254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jash/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n",
      "/home/jash/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in divide\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc_weights gradients iteration 0 example 1 are [[-1428.24803454 -1651.39931108 -1651.39931108 ... -1496.24369735\n",
      "  -1070.02913028 -1070.02913028]\n",
      " [    0.             0.             0.         ...     0.\n",
      "      0.             0.        ]\n",
      " [    0.             0.             0.         ...     0.\n",
      "      0.             0.        ]\n",
      " ...\n",
      " [    0.             0.             0.         ...     0.\n",
      "      0.             0.        ]\n",
      " [    0.             0.             0.         ...     0.\n",
      "      0.             0.        ]\n",
      " [    0.             0.             0.         ...     0.\n",
      "      0.             0.        ]]\n",
      "loss after iteration 0 is 0.33157225337114254\n",
      "fc_weights gradients iteration 0 example 2 are [[-3270.5050878  -3518.51849013 -3518.51849013 ... -3666.51228806\n",
      "  -1884.33563804 -1884.33563804]\n",
      " [    0.             0.             0.         ...     0.\n",
      "      0.             0.        ]\n",
      " [    0.             0.             0.         ...     0.\n",
      "      0.             0.        ]\n",
      " ...\n",
      " [    0.             0.             0.         ...     0.\n",
      "      0.             0.        ]\n",
      " [    0.             0.             0.         ...     0.\n",
      "      0.             0.        ]\n",
      " [    0.             0.             0.         ...     0.\n",
      "      0.             0.        ]]\n",
      "loss after iteration 0 is 0.33157225337114254\n",
      "fc_weights gradients iteration 0 example 3 are [[-71950.87827679 -72267.30976788 -72267.30976788 ... -66434.65062145\n",
      "  -46034.82192217 -46034.82192217]\n",
      " [     0.              0.              0.         ...      0.\n",
      "       0.              0.        ]\n",
      " [     0.              0.              0.         ...      0.\n",
      "       0.              0.        ]\n",
      " ...\n",
      " [     0.              0.              0.         ...      0.\n",
      "       0.              0.        ]\n",
      " [     0.              0.              0.         ...      0.\n",
      "       0.              0.        ]\n",
      " [     0.              0.              0.         ...      0.\n",
      "       0.              0.        ]]\n",
      "loss after iteration 0 is 0.33157225337114254\n",
      "fc_weights gradients iteration 0 example 4 are [[-283520.81006137 -283520.81006137 -285706.62560415 ... -277696.53662119\n",
      "  -166500.90154677 -166500.90154677]\n",
      " [      0.               0.               0.         ...       0.\n",
      "        0.               0.        ]\n",
      " [      0.               0.               0.         ...       0.\n",
      "        0.               0.        ]\n",
      " ...\n",
      " [      0.               0.               0.         ...       0.\n",
      "        0.               0.        ]\n",
      " [      0.               0.               0.         ...       0.\n",
      "        0.               0.        ]\n",
      " [      0.               0.               0.         ...       0.\n",
      "        0.               0.        ]]\n",
      "loss after iteration 0 is 0.33157225337114254\n",
      "fc_weights gradients iteration 0 example 5 are [[-3421916.78744513 -3860541.9640365  -3884466.48652561 ...\n",
      "  -3179561.77278977 -2151377.26901939 -2151377.26901939]\n",
      " [       0.                0.                0.         ...\n",
      "         0.                0.                0.        ]\n",
      " [       0.                0.                0.         ...\n",
      "         0.                0.                0.        ]\n",
      " ...\n",
      " [       0.                0.                0.         ...\n",
      "         0.                0.                0.        ]\n",
      " [       0.                0.                0.         ...\n",
      "         0.                0.                0.        ]\n",
      " [       0.                0.                0.         ...\n",
      "         0.                0.                0.        ]]\n",
      "loss after iteration 0 is 0.33157225337114254\n",
      "fc_weights gradients iteration 0 example 6 are [[-18042905.57231432 -20025178.02241376 -20081739.65830721 ...\n",
      "  -17328136.74211664 -10879540.14913625 -10879540.14913625]\n",
      " [        0.                 0.                 0.         ...\n",
      "          0.                 0.                 0.        ]\n",
      " [        0.                 0.                 0.         ...\n",
      "          0.                 0.                 0.        ]\n",
      " ...\n",
      " [        0.                 0.                 0.         ...\n",
      "          0.                 0.                 0.        ]\n",
      " [        0.                 0.                 0.         ...\n",
      "          0.                 0.                 0.        ]\n",
      " [        0.                 0.                 0.         ...\n",
      "          0.                 0.                 0.        ]]\n",
      "loss after iteration 0 is 0.33157225337114254\n",
      "fc_weights gradients iteration 0 example 7 are [[-1.89015844e+08 -1.95003692e+08 -1.96457552e+08 ... -1.60248964e+08\n",
      "  -1.06738482e+08 -1.06738482e+08]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " ...\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]]\n",
      "loss after iteration 0 is 0.33157225337114254\n",
      "fc_weights gradients iteration 0 example 8 are [[-1.17100849e+09 -1.18526214e+09 -1.19201746e+09 ... -1.00495933e+09\n",
      "  -6.43218801e+08 -6.43218801e+08]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " ...\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]]\n",
      "loss after iteration 0 is 0.33157225337114254\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-c3f539d27bd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxhat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxmu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mivar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msqrtvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforwardlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0msoftmaxgradwrtpower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msoftmaxlossgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfc_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclassifier_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-667d7d20e9e8>\u001b[0m in \u001b[0;36mforwardlayer\u001b[0;34m(f, image, gamma, Beta)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mmaxpoolout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaxpoolout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxhat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxmu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mivar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msqrtvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-be47fbf4c6c6>\u001b[0m in \u001b[0;36mmaxpool\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                             \u001b[0mmaximum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#starting backprop using above functions\n",
    "\n",
    "total_loss=final_loss(target,predicted)\n",
    "m=target.shape[0]\n",
    "w_width=fc_weights.shape[1]\n",
    "alpha=1\n",
    "alpha2=.5\n",
    "alpha3=1\n",
    "alpha4=1\n",
    "numiterations=10\n",
    "convweights=f\n",
    "for e in range(numiterations):\n",
    "        \n",
    "    delta=1e-1\n",
    "    if(loss>delta):\n",
    "        for k in range(m):\n",
    "            \n",
    "            x,xhat,gamma,xmu,ivar,sqrtvar,var,eps=forwardlayer(convweights,image,gamma,Beta)\n",
    "            \n",
    "            softmaxgradwrtpower=softmaxlossgradient(target,predicted,fc_weights,classifier_input)\n",
    "            #updating fc weightstarget,predicted,fc_weights,classifier_input) \n",
    "            gradw=softmaxderivativewrtw(target,predicted,fc_weights,classifier_input,x)\n",
    "            #updating fc weights\n",
    "            gradx=softmaxderivativewrtx(target,predicted,fc_weights,classifier_input,x)\n",
    "            x=1*2+image.shape[1]\n",
    "            a=np.zeros(shape=(image.shape[0],x,x))\n",
    "            a=padding(image,a)   \n",
    "            output=convolve(a,convweights)\n",
    "            \n",
    "            largerderivative=maxpoolderivative(output,gradx,image)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            convweightsgrad,gamma,Beta=convandreluderivativewrtw(output,a,convweights,largerderivative,k,gamma,Beta,alpha3,alpha4,image)\n",
    "            \n",
    "            #updating convweights\n",
    "            \n",
    "            convweights=convweights-alpha2*convweightsgrad/m \n",
    "            \n",
    "            maxpool_out,xhat,gamma,xmu,ivar,sqrtvar,var,eps=forwardlayer(convweights,image,gamma,Beta)\n",
    "            #fc layer\n",
    "            fc_weights=fc_weights-(alpha*gradw)/m\n",
    "            print \"fc_weights gradients iteration\",e,\"example\",k,\"are\",gradw\n",
    "            final_input=maxpool_out.reshape(maxpool_out.shape[0],product)\n",
    "            final_output=np.dot(fc_weights,final_input.T)\n",
    "            final_output=final_output.T\n",
    "            #softmax\n",
    "            classifier_input=softmax(final_output)\n",
    "            predicted=softmax_classifier(classifier_input)\n",
    "            loss=final_loss(target,predicted)        \n",
    "            print \"loss after iteration\",e,\"is\",loss                \n",
    "                                      \n",
    "        if(e>5):\n",
    "            alpha=alpha/2 \n",
    "            alpha2=alpha2/2\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
